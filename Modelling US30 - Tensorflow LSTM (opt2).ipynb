{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import gzip\n",
    "from datetime import datetime, timedelta\n",
    "from statistics import mean, median\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, ReLU, LSTM, Conv1D, Conv2D\n",
    "from tensorflow.keras.activations import sigmoid, tanh\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(varname, filename):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    return df\n",
    "\n",
    "def create_classification_data(df, lookback):\n",
    "    rows = []\n",
    "    columns = ['Date', 'US30_relative_change_perc_1'] # Date and SP500_relative_change_perc_1 from t-0 are added first as target variables \n",
    "    \n",
    "    # create column names based on original with the addition of t-i where i is lookback\n",
    "    for i in range(1, lookback + 1): # starts at 1 since we do not want t-0 variables apart from 'Date' and 'SP500_relative_change_perc_1'\n",
    "        new_columns = df.columns.tolist()[1:] # starts at 1 to exclude 'Date' column\n",
    "        for x in range(len(new_columns)):\n",
    "            new_columns[x] = new_columns[x] + \"_t-\" + str(i)\n",
    "        columns = columns + new_columns\n",
    "    \n",
    "    # create lookback data\n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "        if i > lookback: # lookback cannot be determined for earlier rows\n",
    "            new_row = [row[1][0], row[1][1]] # add target 'Date' and 'SP500_relative_change_perc_1 '\n",
    "            for x in range(1, lookback + 1): # starts at 1 since we do not want t-0 variables apart from 'Date' and 'SP500_relative_change_perc_1'\n",
    "                add_row = df.iloc[i - x].tolist()[1:] # starts at 1 to exclude 'Date' column\n",
    "                new_row = new_row + add_row\n",
    "            rows.append(new_row)\n",
    "    df2 = pd.DataFrame(rows)\n",
    "    df2.columns = columns\n",
    "    return df2\n",
    "\n",
    "def create_train_val_test(df, year_val, year_test, perc_train=None):\n",
    "    if perc_train == None:\n",
    "        # assumes years_train < year_val < year_test\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        \n",
    "        val = df[df['Date'].dt.year == year_val]\n",
    "        test = df[df['Date'].dt.year == year_test]\n",
    "        train = df[df['Date'].dt.year < year_val]\n",
    "    else:\n",
    "        train = df.head(round(len(df) * perc_train))\n",
    "        val = df.tail(len(df) - len(train))\n",
    "        test = val.tail(round(0.5 * len(val)))\n",
    "        val = df.head(len(val) - len(test))\n",
    "    y_train = train['US30_relative_change_perc_1']\n",
    "    x_train = train.drop(['US30_relative_change_perc_1'], axis=1)\n",
    "    \n",
    "    y_val = val['US30_relative_change_perc_1']\n",
    "    x_val = val.drop(['US30_relative_change_perc_1'], axis=1)\n",
    "    \n",
    "    y_test = test['US30_relative_change_perc_1']\n",
    "    x_test = test.drop(['US30_relative_change_perc_1'], axis=1)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "def scale_data(x):\n",
    "    standard_scaler = MinMaxScaler()\n",
    "    x = x.drop([\"Date\"], axis=1)\n",
    "    x_scaled = pd.DataFrame(standard_scaler.fit_transform(x), columns=x.columns)\n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(y):\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    y = list(y)\n",
    "    for dev in y:\n",
    "        if dev >= 0:\n",
    "            positives.append(dev)\n",
    "        else:\n",
    "            negatives.append(dev)\n",
    "    med_pos = median(positives)\n",
    "    med_neg = median(negatives)\n",
    "    \n",
    "    labels = []\n",
    "    for dev in y:\n",
    "        if dev >= 0:\n",
    "            if dev >= med_pos:\n",
    "                labels.append(2)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        else:\n",
    "            if dev <= med_neg:\n",
    "                labels.append(-2)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_transformed_distribution(y):\n",
    "    counts = [0, 0, 0, 0]\n",
    "    for i in range(len(y)):\n",
    "        counts[np.argmax(y[i])] += 1\n",
    "    print(counts)\n",
    "    \n",
    "def one_hot_encode(y):\n",
    "    one_hot = []\n",
    "    for i in y:\n",
    "        if i == -2:\n",
    "            one_hot.append([1,0,0,0])\n",
    "        elif i == -1:\n",
    "            one_hot.append([0,1,0,0])\n",
    "        elif i == 1:\n",
    "            one_hot.append([0,0,1,0])\n",
    "        elif i == 2:\n",
    "            one_hot.append([0,0,0,1])\n",
    "    return np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(object):\n",
    "    def __init__(self, x, activation_functions, batch_sizes):        \n",
    "        self.activation_function = activation_functions[x[0]]\n",
    "        \n",
    "        self.lstm1 = x[1]\n",
    "        self.lstm2 = x[2]\n",
    "        \n",
    "        self.dense1 = x[3]\n",
    "        self.dense2 = x[4]\n",
    "\n",
    "        self.dropout1 = x[5]\n",
    "        self.dropout2 = x[6]\n",
    "        \n",
    "        self.epochs = x[7]\n",
    "        self.batch_size = batch_sizes[x[8]]\n",
    "        \n",
    "        self.lookback = x[9]\n",
    "        \n",
    "    def fit(self):\n",
    "        global df\n",
    "\n",
    "        val_year = 2018\n",
    "        test_year = 2019\n",
    "        df_class = create_classification_data(df, self.lookback)\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = create_train_val_test(df_class, val_year, test_year)\n",
    "\n",
    "\n",
    "        y_train = label_data(y_train)\n",
    "        y_val = label_data(y_val)\n",
    "        y_test = label_data(y_test)\n",
    "\n",
    "        train_date = x_train[['Date']]\n",
    "        x_train = x_train.drop(['Date'], axis=1)\n",
    "        val_date = x_val[['Date']]\n",
    "        x_val = x_val.drop(['Date'], axis=1)\n",
    "        test_date = x_test[['Date']]\n",
    "        x_test = x_test.drop(['Date'], axis=1)\n",
    "\n",
    "        x_train = np.asarray(x_train)\n",
    "        x_val = np.asarray(x_val)\n",
    "        x_test = np.asarray(x_test)\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_val = np.asarray(y_val)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "        x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "        x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "        y_train = one_hot_encode(y_train)\n",
    "        y_val = one_hot_encode(y_val)\n",
    "        y_test = one_hot_encode(y_test)\n",
    "#         determine_transformed_distribution(y_train)\n",
    "#         determine_transformed_distribution(y_val)\n",
    "#         determine_transformed_distribution(y_test)\n",
    "\n",
    "        y_train = y_train.reshape((y_train.shape[0], 1, y_train.shape[1]))\n",
    "        y_val = y_val.reshape((y_val.shape[0], 1, y_val.shape[1]))\n",
    "        y_test = y_test.reshape((y_test.shape[0], 1, y_test.shape[1]))\n",
    "\n",
    "#         print(x_train.shape, y_train.shape)\n",
    "#         print(x_val.shape, y_val.shape)\n",
    "#         print(x_test.shape, y_test.shape)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.lstm1, dropout=self.dropout1, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "        if self.lstm2 > 0:\n",
    "            model.add(LSTM(self.lstm2, dropout=self.dropout2, return_sequences=True))\n",
    "        if self.dense1 > 0:\n",
    "            model.add(Dense(self.dense1, activation=self.activation_function))\n",
    "        if self.dense2 > 0:\n",
    "            model.add(Dense(self.dense2, activation=self.activation_function))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"acc\"])\n",
    "        history = model.fit(x_train, y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0, validation_data=(x_val, y_val), shuffle=False)\n",
    "        \n",
    "        val_loss = mean(history.history['val_acc'][-5:])\n",
    "#         val_loss = history.history['val_acc'][-1]\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(val_loss):\n",
    "    fitness = val_loss\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EA(object):\n",
    "    def __init__(self, population_size, activation_functions, batch_sizes):\n",
    "        self.population_size = population_size\n",
    "        self.a = 0.2\n",
    "        self.activation_functions = activation_functions\n",
    "        self.batch_sizes = batch_sizes\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        \"\"\"\n",
    "        include in fitness function\n",
    "            relative difference between train_loss and val_loss (smaller is better)\n",
    "            number of layers (smaller is better)\n",
    "            bottleneck size (smaller is better)\n",
    "            val_loss (smaller is better)\n",
    "        \n",
    "        \"\"\"\n",
    "        lstm = LSTM_model(x, self.activation_functions, self.batch_sizes)\n",
    "        val_loss = lstm.fit()\n",
    "        fitness = calculate_fitness(val_loss)\n",
    "        return fitness\n",
    "    \n",
    "    def select_triple(self, candidate, population):\n",
    "        # select three random instances for differential evolution\n",
    "        x1, x2, x3 = np.random.choice(range(len(population))), np.random.choice(range(len(population))), np.random.choice(range(len(population)))\n",
    "        while candidate == x1 or candidate == x2 or candidate == x3 or x1 == x2 or x2 == x3 or x1 == x3:\n",
    "            # keep selecting new ones until candidate != x1 != x2 != x3\n",
    "            x1, x2, x3 = np.random.choice(range(len(population))), np.random.choice(range(len(population))), np.random.choice(range(len(population)))\n",
    "        return population[x1], population[x2], population[x3]\n",
    "    \n",
    "    def mutate(self, x1, x2, x3):\n",
    "        mutated = x1 + (self.a * (x3 - x2))\n",
    "#         print(f\"mutated {mutated}\")\n",
    "        # activation function\n",
    "        mutated[0] = round(mutated[0])\n",
    "        mutated[0] = min(mutated[0], len(self.activation_functions) - 1)\n",
    "        mutated[0] = max(0, mutated[0])\n",
    "        \n",
    "        # lstm layer 1\n",
    "        mutated[1] = round(mutated[1])\n",
    "        mutated[1] = max(1, mutated[1]) # must be at least one\n",
    "\n",
    "        # lstm layer 2\n",
    "        mutated[2] = round(mutated[2])\n",
    "        mutated[2] = max(0, mutated[2])\n",
    "\n",
    "        # dense layer 1\n",
    "        mutated[3] = round(mutated[3])\n",
    "        mutated[3] = max(4, mutated[3])\n",
    "        \n",
    "        # dense layer 2\n",
    "        mutated[4] = round(mutated[4])\n",
    "        mutated[4] = max(4, mutated[4])\n",
    "\n",
    "        # dropout lstm layer 1\n",
    "        mutated[5] = max(0.05, mutated[5])\n",
    "        mutated[5] = min(0.95, mutated[5])\n",
    "        mutated[5] = round(mutated[5],2)\n",
    "        \n",
    "        # dropout lstm layer 2\n",
    "        mutated[6] = max(0.05, mutated[6])\n",
    "        mutated[6] = min(0.95, mutated[6])\n",
    "        mutated[6] = round(mutated[6],2)\n",
    "        \n",
    "        # epochs\n",
    "        mutated[7] = round(mutated[7])\n",
    "        mutated[7] = max(6, mutated[7])\n",
    "\n",
    "        # batch size\n",
    "        mutated[8] = round(mutated[8])\n",
    "        mutated[8] = min(mutated[8], len(self.batch_sizes) - 1)\n",
    "        mutated[8] = max(0, mutated[8])\n",
    "        \n",
    "        mutated[9] = round(mutated[9])\n",
    "        mutated[9] = max(1, mutated[9])\n",
    "        \n",
    "        return mutated\n",
    "        \n",
    "    def recombine(self, candidate, mutation):\n",
    "        for i in range(candidate.shape[0]):\n",
    "            prob = np.random.randint(0, 2)\n",
    "            if prob == 1:\n",
    "                candidate[i] = mutation[i]\n",
    "        return candidate\n",
    "\n",
    "    def select(self, x_new, f_new, x_old, f_old):\n",
    "        x_cat = np.concatenate([x_new, x_old], 0)\n",
    "        f_cat = np.concatenate([f_new, f_old])\n",
    "        ind = np.argsort(f_cat)\n",
    "        x = x_cat[ind]\n",
    "        f = f_cat[ind]\n",
    "        return x[-self.population_size:], f[-self.population_size:]\n",
    "    \n",
    "    def step(self, x_old, f_old):\n",
    "        x = np.copy(x_old)\n",
    "        f = np.copy(f_old)\n",
    "        for i in tqdm(range(self.population_size), total=self.population_size):\n",
    "            # choose candidate\n",
    "            candidate = x[i]\n",
    "            # select 3 instances for differential evolution\n",
    "            x1, x2, x3 = self.select_triple(i, x)\n",
    "            # mutate 3 instances\n",
    "            mutated_triple = self.mutate(x1, x2, x3)\n",
    "            # recombine candidate with mutation\n",
    "            candidate = self.recombine(candidate, mutated_triple)\n",
    "            x[i] = candidate\n",
    "            # evaluate candidate solution\n",
    "            f_candidate = self.evaluate(candidate)\n",
    "            f[i] = f_candidate\n",
    "        # select survivors\n",
    "        x, f = self.select(x, f, x_old, f_old)\n",
    "        return x, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_population(population_size, activation_functions, batch_sizes):\n",
    "    # generate initial population\n",
    "    population = []\n",
    "    print(\"Creating initial population...\")\n",
    "    for i in tqdm(range(population_size), total=population_size):\n",
    "        activation_function = random.randint(0, len(activation_functions) - 1)\n",
    "        \n",
    "        lookback = random.randint(1, 20)\n",
    "        \n",
    "        variables = lookback * 18\n",
    "        \n",
    "        lstm1 = random.randint(1, 1.5 * variables)\n",
    "        lstm2 = random.randint(0, 1.5 * variables)\n",
    "        dense1 = random.randint(4, 1.5 * variables)\n",
    "        dense2 = random.randint(4, 1.5 * variables)\n",
    "        \n",
    "        dropout1 = round(random.uniform(0.05, 0.95),2)\n",
    "        dropout2 = round(random.uniform(0.05, 0.95),2)\n",
    "\n",
    "        epochs = random.randint(10, 500)\n",
    "        \n",
    "        batch_size = random.randint(0, len(batch_sizes) - 1)\n",
    "    \n",
    "        population.append(np.asarray([activation_function, lstm1, lstm2, dense1, dense2, dropout1, dropout2, epochs, batch_size, lookback], dtype='object'))\n",
    "    print(\"Initial population ready\")\n",
    "    return np.asarray(population)\n",
    "\n",
    "def evaluate_init_population(ea, x):\n",
    "    # evaluate initial population\n",
    "    f = []\n",
    "    print(\"Evaluating initial population...\")\n",
    "    for i in tqdm(range(x.shape[0]), total=x.shape[0]):\n",
    "        instance = x[i]\n",
    "        f.append(ea.evaluate(instance))\n",
    "    print(\"Evaluation initial population completed\")\n",
    "    return np.asarray(f)\n",
    "\n",
    "def print_best(x, activation_functions, batch_sizes, fitness):\n",
    "    print(f\"\\nMost suitable parameters -- Accuracy of {fitness}:\")\n",
    "    print(f\"\\tActivation function:           \\t{activation_functions[x[0]]}\")\n",
    "    print(f\"\\tLSTM nodes layer 1:            \\t{x[1]}\")\n",
    "    print(f\"\\tLSTM nodes layer 2:            \\t{x[2]}\")\n",
    "    print(f\"\\tDense nodes layer 1:           \\t{x[3]}\")\n",
    "    print(f\"\\tDense nodes layer 2:           \\t{x[4]}\")\n",
    "    print(f\"\\tDropout LSTM layer 1:          \\t{x[5]}\")\n",
    "    print(f\"\\tDropout LSTM layer 2:          \\t{x[6]}\")\n",
    "    print(f\"\\tEpochs trained:                \\t{x[7]}\")\n",
    "    print(f\"\\tBatch Size:                    \\t{batch_sizes[x[8]]}\")\n",
    "    print(f\"\\tLookback:                      \\t{x[9]}\")\n",
    "\n",
    "def plot_convergence(f_best):\n",
    "    fig1 = make_subplots(rows=1, cols=1, specs=[[{'type':'xy'}]])\n",
    "    \n",
    "    x_values = []\n",
    "    for i in range(len(f_best)):\n",
    "        x_values.append(i)\n",
    "    fig1.add_trace(go.Scatter(x=x_values, y=f_best, mode=\"lines\"), row=1, col=1)\n",
    "\n",
    "    fig1.update_layout(\n",
    "        title = f'Validation Accuracy Over Autoencoder Tuning Generations', \n",
    "        xaxis1 = dict(title_text = 'Generation'),\n",
    "        yaxis1 = dict(title_text = \"Validation Accuracy\")\n",
    "    )\n",
    "    fig1.write_image(\"Plots/opt lstm 2 us30.png\")\n",
    "    fig1.show()\n",
    "\n",
    "def validate_best(x, ea):\n",
    "    print(\"\\nValidating solution...\")\n",
    "    ea.evaluate(x)\n",
    "    print(\"Solution validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 23327.61it/s]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial population...\n",
      "Initial population ready\n",
      "Evaluating initial population...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:20:16.684393: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-29 13:20:16.684846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-29 13:20:17.378634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [42:22<00:00, 84.76s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation initial population completed\n",
      "--> STARTING EVOLUTION\n",
      "Generation: 0\tBest fitness: 0.35936256051063536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 30/30 [50:55<00:00, 101.84s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 197 150 212 55 0.7 0.15 401 0 8]\n",
      " [1 226 2 180 258 0.53 0.29 257 0 12]\n",
      " [1 148 177 198 208 0.57 0.22 38 0 9]\n",
      " [1 148 212 214 170 0.93 0.84 38 1 9]\n",
      " [0 50 308 78 228 0.31 0.74 408 1 10]\n",
      " [1 69 30 257 150 0.88 0.47 500 1 14]\n",
      " [1 420 347 418 392 0.94 0.66 361 1 18]\n",
      " [1 334 492 418 358 0.94 0.66 547 1 18]\n",
      " [0 27 116 26 84 0.37 0.91 31 0 8]\n",
      " [1 226 236 11 200 0.77 0.19 152 1 15]\n",
      " [0 245 448 372 321 0.77 0.24 327 0 14]\n",
      " [1 156 117 90 169 0.83 0.81 472 0 7]\n",
      " [1 45 34 257 29 0.88 0.87 500 1 3]\n",
      " [1 206 163 221 224 0.89 0.83 89 0 10]\n",
      " [0 82 96 64 529 0.88 0.12 490 1 20]\n",
      " [1 239 115 188 105 0.73 0.06 367 1 14]\n",
      " [1 80 3 92 25 0.77 0.05 126 2 12]\n",
      " [1 234 145 80 214 0.89 0.78 429 0 17]\n",
      " [0 20 333 352 253 0.31 0.61 420 1 14]\n",
      " [0 82 269 64 529 0.88 0.12 490 1 20]\n",
      " [1 34 270 43 221 0.95 0.87 443 1 17]\n",
      " [1 234 237 24 85 0.47 0.78 429 0 17]\n",
      " [1 81 91 82 66 0.57 0.81 34 2 5]\n",
      " [1 314 151 130 69 0.9 0.56 259 2 17]\n",
      " [1 60 204 437 479 0.6 0.21 80 0 18]\n",
      " [1 17 179 298 6 0.4 0.74 425 1 12]\n",
      " [0 80 3 92 25 0.77 0.68 126 2 4]\n",
      " [1 177 130 177 47 0.84 0.14 455 0 7]\n",
      " [0 17 179 298 6 0.4 0.74 80 1 12]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]]\n",
      "Generation: 1\tBest fitness: 0.36334662437438964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 30/30 [1:06:33<00:00, 133.12s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 156 117 90 169 0.83 0.81 472 0 7]\n",
      " [1 45 34 257 29 0.88 0.87 500 1 3]\n",
      " [1 239 115 188 105 0.73 0.06 367 1 14]\n",
      " [0 82 96 64 529 0.88 0.12 490 1 20]\n",
      " [0 50 308 273 124 0.31 0.74 408 1 12]\n",
      " [1 215 212 63 210 0.88 0.84 363 1 16]\n",
      " [1 80 3 92 25 0.77 0.05 126 2 12]\n",
      " [1 234 145 80 214 0.89 0.78 429 0 17]\n",
      " [0 20 333 352 253 0.31 0.61 420 1 14]\n",
      " [1 60 85 16 137 0.35 0.74 6 0 18]\n",
      " [1 420 347 418 59 0.94 0.66 361 0 18]\n",
      " [1 91 100 80 214 0.89 0.78 429 0 3]\n",
      " [0 314 151 90 105 0.9 0.53 259 2 17]\n",
      " [1 156 117 76 131 0.38 0.89 472 0 7]\n",
      " [0 82 269 64 529 0.88 0.12 490 1 20]\n",
      " [1 34 270 43 221 0.95 0.87 443 1 17]\n",
      " [1 234 237 24 85 0.47 0.78 429 0 17]\n",
      " [1 81 91 82 66 0.57 0.81 34 2 5]\n",
      " [1 17 179 298 6 0.4 0.74 425 1 12]\n",
      " [1 60 204 437 479 0.6 0.21 80 0 18]\n",
      " [1 314 151 130 69 0.9 0.56 259 2 17]\n",
      " [1 69 169 257 150 0.95 0.47 500 2 14]\n",
      " [1 80 3 92 25 0.77 0.54 171 2 12]\n",
      " [0 80 3 92 25 0.77 0.68 126 2 4]\n",
      " [0 17 179 298 6 0.4 0.74 80 1 12]\n",
      " [1 69 53 418 57 0.9 0.66 547 1 5]\n",
      " [1 177 130 177 47 0.84 0.14 455 0 7]\n",
      " [1 34 270 14 151 0.95 0.15 83 1 14]\n",
      " [0 17 179 298 68 0.71 0.74 80 0 13]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]]\n",
      "Generation: 2\tBest fitness: 0.36334662437438964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [47:43<00:00, 95.44s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 420 347 418 59 0.94 0.66 361 0 18]\n",
      " [1 297 145 102 214 0.79 0.78 429 0 17]\n",
      " [1 91 100 80 214 0.89 0.78 429 0 3]\n",
      " [0 314 151 90 105 0.9 0.53 259 2 17]\n",
      " [1 156 117 76 131 0.38 0.89 472 0 7]\n",
      " [0 82 269 64 529 0.88 0.12 490 1 20]\n",
      " [1 146 130 128 47 0.84 0.78 379 0 7]\n",
      " [1 34 270 43 221 0.95 0.87 443 1 17]\n",
      " [0 50 96 64 150 0.88 0.74 490 1 20]\n",
      " [1 234 237 24 85 0.47 0.78 429 0 17]\n",
      " [0 129 179 298 6 0.43 0.91 80 1 12]\n",
      " [1 81 91 82 66 0.57 0.81 34 2 5]\n",
      " [1 69 169 257 150 0.95 0.47 500 2 14]\n",
      " [1 314 151 130 69 0.9 0.56 259 2 17]\n",
      " [1 60 204 437 479 0.6 0.21 80 0 18]\n",
      " [1 82 10 90 38 0.87 0.41 490 2 20]\n",
      " [0 314 275 59 105 0.9 0.53 259 2 17]\n",
      " [1 17 179 298 6 0.4 0.74 425 1 12]\n",
      " [0 80 3 92 25 0.77 0.68 126 2 4]\n",
      " [1 135 56 128 16 0.57 0.38 34 2 5]\n",
      " [1 80 3 92 25 0.77 0.54 171 2 12]\n",
      " [1 69 53 418 57 0.9 0.66 547 1 5]\n",
      " [0 17 179 298 6 0.4 0.74 80 1 12]\n",
      " [1 177 130 177 47 0.84 0.14 455 0 7]\n",
      " [1 34 270 14 151 0.95 0.15 83 1 14]\n",
      " [0 17 179 298 68 0.71 0.74 80 0 13]\n",
      " [0 103 77 28 25 0.87 0.68 126 1 4]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]\n",
      " [1 156 117 121 169 0.56 0.81 472 2 6]\n",
      " [1 93 126 90 69 0.78 0.57 335 0 5]]\n",
      "Generation: 3\tBest fitness: 0.37051793932914734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [30:52<00:00, 61.75s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 129 179 298 6 0.43 0.91 80 1 12]\n",
      " [1 166 38 185 69 0.78 0.32 472 0 5]\n",
      " [1 81 91 82 66 0.57 0.81 34 2 5]\n",
      " [1 314 151 130 69 0.9 0.56 259 2 17]\n",
      " [0 314 275 59 105 0.9 0.53 259 2 17]\n",
      " [1 82 10 90 38 0.87 0.41 490 2 20]\n",
      " [1 60 204 437 479 0.6 0.21 80 0 18]\n",
      " [1 69 169 257 150 0.95 0.47 500 2 14]\n",
      " [1 17 179 298 6 0.4 0.74 425 1 12]\n",
      " [1 135 56 128 16 0.57 0.38 34 2 5]\n",
      " [0 80 3 92 25 0.77 0.68 126 2 4]\n",
      " [1 80 3 92 25 0.77 0.54 171 2 12]\n",
      " [1 69 53 418 57 0.9 0.66 547 1 5]\n",
      " [0 17 179 298 6 0.4 0.74 80 1 12]\n",
      " [1 177 130 177 47 0.84 0.14 455 0 7]\n",
      " [1 34 270 14 151 0.95 0.15 83 1 14]\n",
      " [0 17 179 298 68 0.71 0.74 80 0 13]\n",
      " [0 36 77 28 491 0.8 0.39 126 1 4]\n",
      " [0 61 3 114 60 0.77 0.93 466 0 4]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]\n",
      " [1 49 10 395 38 0.91 0.41 490 1 5]\n",
      " [0 103 77 28 25 0.87 0.68 126 1 4]\n",
      " [1 17 179 298 4 0.4 0.74 425 1 5]\n",
      " [1 160 96 52 81 0.88 0.85 554 2 6]\n",
      " [1 177 130 96 26 0.84 0.83 455 0 5]\n",
      " [1 24 204 269 479 0.84 0.48 278 0 18]\n",
      " [1 80 167 92 53 0.77 0.78 171 2 12]\n",
      " [1 76 78 94 57 0.9 0.84 489 0 5]\n",
      " [1 156 117 121 169 0.56 0.81 472 2 6]\n",
      " [1 93 126 90 69 0.78 0.57 335 0 5]]\n",
      "Generation: 4\tBest fitness: 0.37051793932914734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [27:07<00:00, 54.24s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 80 3 92 25 0.77 0.68 126 2 4]\n",
      " [1 135 56 128 16 0.57 0.38 34 2 5]\n",
      " [1 177 130 177 47 0.84 0.14 455 0 7]\n",
      " [0 17 179 298 6 0.4 0.74 80 1 12]\n",
      " [1 93 97 90 53 0.7 0.81 472 0 5]\n",
      " [1 69 53 418 57 0.9 0.66 547 1 5]\n",
      " [1 34 270 14 151 0.95 0.15 83 1 14]\n",
      " [1 14 10 90 38 0.4 0.71 490 2 5]\n",
      " [0 36 77 28 491 0.8 0.39 126 1 4]\n",
      " [0 17 179 298 68 0.71 0.74 80 0 13]\n",
      " [0 61 3 114 60 0.77 0.93 466 0 4]\n",
      " [0 103 77 28 25 0.87 0.68 126 1 4]\n",
      " [1 74 151 155 47 0.78 0.7 262 2 5]\n",
      " [1 49 10 395 38 0.91 0.41 490 1 5]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]\n",
      " [1 160 96 52 81 0.88 0.85 554 2 6]\n",
      " [1 17 179 298 4 0.4 0.74 425 1 5]\n",
      " [1 103 151 268 44 0.95 0.68 464 2 4]\n",
      " [1 156 117 162 4 0.84 0.52 472 2 6]\n",
      " [0 177 115 36 82 0.84 0.83 219 2 5]\n",
      " [1 177 130 96 26 0.84 0.83 455 0 5]\n",
      " [1 24 204 269 479 0.84 0.48 278 0 18]\n",
      " [1 80 167 92 53 0.77 0.78 171 2 12]\n",
      " [0 314 126 59 75 0.9 0.53 259 2 5]\n",
      " [0 73 126 159 34 0.8 0.68 126 2 6]\n",
      " [1 76 78 94 57 0.9 0.84 489 0 5]\n",
      " [1 156 117 121 169 0.56 0.81 472 2 6]\n",
      " [1 76 135 94 57 0.9 0.84 489 0 5]\n",
      " [1 93 126 90 69 0.78 0.57 335 0 5]\n",
      " [1 46 204 134 26 0.84 0.48 278 2 6]]\n",
      "Generation: 5\tBest fitness: 0.3729083776473999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [31:48<00:00, 63.62s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 161 77 47 25 0.87 0.68 126 2 4]\n",
      " [1 49 10 395 38 0.91 0.41 490 1 5]\n",
      " [0 103 77 28 25 0.87 0.68 126 1 4]\n",
      " [1 74 151 155 47 0.78 0.7 262 2 5]\n",
      " [1 93 117 90 69 0.78 0.81 472 0 5]\n",
      " [0 177 115 36 82 0.84 0.83 219 2 5]\n",
      " [1 156 117 162 4 0.84 0.52 472 2 6]\n",
      " [1 103 151 268 44 0.95 0.68 464 2 4]\n",
      " [1 17 179 298 4 0.4 0.74 425 1 5]\n",
      " [1 160 96 52 81 0.88 0.85 554 2 6]\n",
      " [1 177 130 96 26 0.84 0.83 455 0 5]\n",
      " [1 24 204 269 479 0.84 0.48 278 0 18]\n",
      " [1 80 167 92 53 0.77 0.78 171 2 12]\n",
      " [1 24 161 98 479 0.77 0.78 278 0 12]\n",
      " [1 93 126 90 69 0.88 0.71 335 0 5]\n",
      " [0 314 126 59 75 0.9 0.53 259 2 5]\n",
      " [0 73 126 159 34 0.8 0.68 126 2 6]\n",
      " [1 47 20 456 38 0.93 0.32 454 1 5]\n",
      " [1 76 78 94 57 0.9 0.84 489 0 5]\n",
      " [1 135 113 61 72 0.89 0.78 34 2 6]\n",
      " [1 76 135 94 57 0.9 0.84 489 0 5]\n",
      " [1 156 117 121 169 0.56 0.81 472 2 6]\n",
      " [1 93 126 90 69 0.78 0.57 335 0 5]\n",
      " [1 76 132 94 50 0.86 0.84 385 0 6]\n",
      " [1 80 3 92 58 0.88 0.68 487 2 4]\n",
      " [1 46 204 134 26 0.84 0.48 278 2 6]\n",
      " [1 40 234 104 110 0.83 0.48 262 2 5]\n",
      " [1 93 97 90 66 0.82 0.81 292 0 5]\n",
      " [0 76 152 177 47 0.83 0.66 455 2 6]\n",
      " [1 156 117 162 105 0.84 0.51 472 2 5]]\n",
      "Generation: 6\tBest fitness: 0.3784860670566559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [28:23<00:00, 56.78s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 177 115 182 82 0.84 0.47 219 2 6]\n",
      " [1 160 96 52 81 0.88 0.85 554 2 6]\n",
      " [1 139 117 162 67 0.84 0.52 6 2 6]\n",
      " [1 177 130 96 26 0.84 0.83 455 0 5]\n",
      " [1 24 204 269 479 0.84 0.48 278 0 18]\n",
      " [1 18 234 104 465 0.79 0.48 217 2 13]\n",
      " [1 80 167 92 53 0.77 0.78 171 2 12]\n",
      " [1 93 126 90 69 0.88 0.71 335 0 5]\n",
      " [1 24 161 98 479 0.77 0.78 278 0 12]\n",
      " [1 160 219 123 81 0.88 0.85 346 2 6]\n",
      " [0 73 126 159 34 0.8 0.68 126 2 6]\n",
      " [1 76 107 94 67 0.79 0.84 489 0 5]\n",
      " [0 314 126 59 75 0.9 0.53 259 2 5]\n",
      " [1 76 78 94 57 0.9 0.84 489 0 5]\n",
      " [1 135 113 61 72 0.89 0.78 34 2 6]\n",
      " [1 47 20 456 38 0.93 0.32 454 1 5]\n",
      " [1 76 135 94 57 0.9 0.84 489 0 5]\n",
      " [1 156 117 121 169 0.56 0.81 472 2 6]\n",
      " [1 161 77 184 25 0.83 0.45 126 2 4]\n",
      " [1 93 126 102 69 0.88 0.71 335 2 5]\n",
      " [0 93 97 96 66 0.78 0.81 292 2 5]\n",
      " [1 93 126 90 69 0.78 0.57 335 0 5]\n",
      " [1 76 132 94 50 0.86 0.84 385 0 6]\n",
      " [1 80 3 92 58 0.88 0.68 487 2 4]\n",
      " [1 46 204 134 26 0.84 0.48 278 2 6]\n",
      " [1 40 234 104 110 0.83 0.48 262 2 5]\n",
      " [1 93 97 90 66 0.82 0.81 292 0 5]\n",
      " [0 76 152 177 47 0.83 0.66 455 2 6]\n",
      " [1 76 135 94 49 0.9 0.89 376 0 5]\n",
      " [1 156 117 162 105 0.84 0.51 472 2 5]]\n",
      "Generation: 7\tBest fitness: 0.3784860670566559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████▊             | 25/30 [1:12:14<14:26, 173.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jr/swvxxh453l3_0psw7xssft500000gn/T/ipykernel_25767/3372844712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Generation: {i}\\tBest fitness: {f.max()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpopulations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jr/swvxxh453l3_0psw7xssft500000gn/T/ipykernel_25767/3175427835.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x_old, f_old)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# evaluate candidate solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mf_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# select survivors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jr/swvxxh453l3_0psw7xssft500000gn/T/ipykernel_25767/3175427835.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \"\"\"\n\u001b[1;32m     17\u001b[0m         \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jr/swvxxh453l3_0psw7xssft500000gn/T/ipykernel_25767/3199037754.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mval_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtest_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdf_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_classification_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jr/swvxxh453l3_0psw7xssft500000gn/T/ipykernel_25767/812214244.py\u001b[0m in \u001b[0;36mcreate_classification_data\u001b[0;34m(df, lookback)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# create lookback data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# lookback cannot be determined for earlier rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# add target 'Date' and 'SP500_relative_change_perc_1 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    275\u001b[0m                                        raise_cast_failure=True)\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   4639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4641\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4643\u001b[0m                 raise ValueError(\"cannot create SingleBlockManager with more \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = retrieve_data(\"SP500\", \"Dataset v3/US30_reduced_data_20220425.csv\")\n",
    "\n",
    "population_size = 30\n",
    "generations = 30\n",
    "activation_functions = ['sigmoid', 'tanh']\n",
    "batch_sizes = [64, 128, 256]\n",
    "\n",
    "ea = EA(population_size, activation_functions, batch_sizes)\n",
    "x = init_population(population_size, activation_functions, batch_sizes)\n",
    "f = evaluate_init_population(ea, x)\n",
    "\n",
    "populations = []\n",
    "populations.append(x)\n",
    "f_best = [f.max()]\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "print(\"--> STARTING EVOLUTION\")\n",
    "early_stop = 0\n",
    "for i in range(generations):\n",
    "    print(f'Generation: {i}\\tBest fitness: {f.max()}')\n",
    "    x, f = ea.step(x, f)\n",
    "    print(x)\n",
    "    populations.append(x)\n",
    "\n",
    "    if f.max() > f_best[-1]:\n",
    "        f_best.append(f.max())\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        f_best.append(f_best[-1])\n",
    "        early_stop += 1\n",
    "    if early_stop == 3:\n",
    "        print(\"Early stop triggered at generation {i} after not improving fitness for three generations\")\n",
    "        break\n",
    "print(\"--> EVOLUTION FINISHED\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "evolution_time = end_time - start_time\n",
    "evolution_time_seconds = evolution_time.total_seconds()\n",
    "print(f\"\\nElapsed time in minutes: {evolution_time_seconds/60}\")\n",
    "\n",
    "print(f)\n",
    "print(f.min())\n",
    "index_best_parameters = np.where(f == f.max())[0][0]\n",
    "print(index_best_parameters)\n",
    "print_best(x[index_best_parameters], activation_functions, batch_sizes, f.max())\n",
    "validate_best(x[index_best_parameters], ea)\n",
    "plot_convergence(f_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(f_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
