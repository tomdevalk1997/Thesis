{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import gzip\n",
    "from datetime import datetime, timedelta\n",
    "from statistics import mean, median\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, ReLU, LSTM, Conv1D, Conv2D\n",
    "from tensorflow.keras.activations import sigmoid, tanh\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(filename):\n",
    "    model = tf.models.load_model(filename)\n",
    "    return model\n",
    "    \n",
    "def retrieve_data(filename):\n",
    "    if \"combined\" in filename:\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, index_col=0)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    return df\n",
    "\n",
    "def create_classification_data(df, lookback, column):\n",
    "    rows = []\n",
    "    columns = ['Date', column] # Date and SP500_relative_change_perc_1 from t-0 are added first as target variables \n",
    "    # create column names based on original with the addition of t-i where i is lookback\n",
    "    for i in range(1, lookback + 1): # starts at 1 since we do not want t-0 variables apart from 'Date' and 'SP500_relative_change_perc_1'\n",
    "        new_columns = df.columns.tolist() # starts at 1 to exclude 'Date' column\n",
    "        for x in range(len(new_columns)):\n",
    "            new_columns[x] = new_columns[x] + \"_t-\" + str(i)\n",
    "        columns = columns + new_columns\n",
    "    \n",
    "    # create lookback data\n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "        if i > lookback: # lookback cannot be determined for earlier rows\n",
    "            new_row = [row[1]['Date'], row[1][column]]\n",
    "#             new_row = [row[1][0], row[1][1]] # add target 'Date' and 'SP500_relative_change_perc_1 '\n",
    "            for x in range(1, lookback + 1): # starts at 1 since we do not want t-0 variables apart from 'Date' and 'SP500_relative_change_perc_1'\n",
    "                add_row = df.iloc[i - x].tolist() # starts at 1 to exclude 'Date' column\n",
    "                new_row = new_row + add_row\n",
    "            rows.append(new_row)\n",
    "    \n",
    "    df2 = pd.DataFrame(rows)\n",
    "    df2.columns = columns\n",
    "                       \n",
    "    for col in columns:\n",
    "        if col[:4] == \"Date\" and col != \"Date\":\n",
    "            df2 = df2.drop([col], axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mag_sp500 = ['SP500_week_high_1_t-2', 'SP500_stochastic_K_50_t-1', 'SP500_week_low_1_t-1']\n",
    "features_mag_us30 = ['US30_stochastic_K_20_t-1', 'US30_week_high_1_t-3', 'US30_ATR5_t-2']\n",
    "features_mag_nasdaq = ['NASDAQ_F_Volume_t-1', 'NASDAQ_stochastic_K_50_t-3', 'HS50_F_relative_change_perc_50_t-1', 'CAC40_relative_change_perc_50_t-1', 'NASDAQ_stochastic_K_50_t-1', 'NASDAQ_week_low_1_t-1', 'USDCHF_relative_change_perc_5_t-1', 'NASDAQ_stochastic_K_10_t-1', 'EURUSD_relative_change_perc_1_t-3', 'US30_relative_change_perc_5_t-3']\n",
    "features_mag_sp500.insert(0, 'SP500_relative_change_perc_1')\n",
    "features_mag_sp500.insert(0, 'Date')\n",
    "features_mag_us30.insert(0, 'US30_relative_change_perc_1')\n",
    "features_mag_us30.insert(0, 'Date')\n",
    "features_mag_nasdaq.insert(0, 'NASDAQ_relative_change_perc_1')\n",
    "features_mag_nasdaq.insert(0, 'Date')\n",
    "\n",
    "data_mag_sp500 = create_classification_data(retrieve_data(\"Dataset v3/SP500_combined_data_20220422.csv\"), 3, 'SP500_relative_change_perc_1')\n",
    "data_mag_us30 = create_classification_data(retrieve_data(\"Dataset v3/US30_combined_data_20220422.csv\"), 3, 'US30_relative_change_perc_1')\n",
    "data_mag_nasdaq = create_classification_data(retrieve_data(\"Dataset v3/nasdaq_combined_data_20220422.csv\"), 3, 'NASDAQ_relative_change_perc_1')\n",
    "\n",
    "data_mag_sp500 = data_mag_sp500[features_mag_sp500]\n",
    "data_mag_us30 = data_mag_us30[features_mag_us30]\n",
    "data_mag_nasdaq = data_mag_nasdaq[features_mag_nasdaq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(y):\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    y = list(y)\n",
    "    for dev in y:\n",
    "        if dev >= 0:\n",
    "            positives.append(dev)\n",
    "        else:\n",
    "            negatives.append(dev)\n",
    "    med_pos = median(positives)\n",
    "    med_neg = median(negatives)\n",
    "    \n",
    "    labels = []\n",
    "    for dev in y:\n",
    "        if dev >= med_pos or dev <= med_neg:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels\n",
    "# \n",
    "data_mag_sp500['label'] = label_data(data_mag_sp500['SP500_relative_change_perc_1'])\n",
    "data_mag_us30['label'] = label_data(data_mag_us30['US30_relative_change_perc_1'])\n",
    "data_mag_nasdaq['label'] = label_data(data_mag_nasdaq['NASDAQ_relative_change_perc_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data_mag_sp500['pred'] = data_mag_sp500['label'].shift(1)\n",
    "data_mag_sp500 = data_mag_sp500[1:]\n",
    "data_mag_sp500['pred'] = data_mag_sp500['pred'].astype(int)\n",
    "\n",
    "data_mag_us30['pred'] = data_mag_us30['label'].shift(1)\n",
    "data_mag_us30 = data_mag_us30[1:]\n",
    "data_mag_us30['pred'] = data_mag_us30['pred'].astype(int)\n",
    "\n",
    "data_mag_nasdaq['pred'] = data_mag_nasdaq['label'].shift(1)\n",
    "data_mag_nasdaq = data_mag_nasdaq[1:]\n",
    "data_mag_nasdaq['pred'] = data_mag_nasdaq['pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5517564402810304\n",
      "0.5179282868525896\n",
      "0.5753968253968254\n",
      "\n",
      "\n",
      "0.5585205992509363\n",
      "0.5378486055776892\n",
      "0.5476190476190477\n",
      "\n",
      "\n",
      "0.5543071161048689\n",
      "0.549800796812749\n",
      "0.5119047619047619\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def train_val_test_acc(df):\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    val = df[df['Date'].dt.year == 2018]\n",
    "    test = df[df['Date'].dt.year == 2019]\n",
    "    train = df[df['Date'].dt.year < 2018]\n",
    "    \n",
    "    train_acc = accuracy(train['label'], train['pred'])\n",
    "    val_acc = accuracy(val['label'], val['pred'])\n",
    "    test_acc = accuracy(test['label'], test['pred'])\n",
    "    print(train_acc)\n",
    "    print(val_acc)\n",
    "    print(test_acc)\n",
    "    print(\"\\n\")\n",
    "train_val_test_acc(data_mag_sp500)\n",
    "train_val_test_acc(data_mag_us30)\n",
    "train_val_test_acc(data_mag_nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
